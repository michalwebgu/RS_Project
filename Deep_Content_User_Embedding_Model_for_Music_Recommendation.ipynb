{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Content-User Embedding Model for Music Recommendation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyZIaUBDTSdW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "122de21b-1e77-4e89-9d08-ac56d0d573b5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2J_ZSX3EDT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import math\n",
        "import statistics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.utils import Sequence\n",
        "from keras.layers import Conv1D, MaxPool1D, BatchNormalization, GlobalAvgPool1D, Dense, Dropout, Activation, Reshape, Input, Concatenate, dot, Add, Flatten, concatenate, Embedding, add\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r93pcGJW4dod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOr8fglSTXDT",
        "colab_type": "text"
      },
      "source": [
        "# **Original Model**\n",
        "An implementation of the model as described in the *Deep Content-User Embedding Model for Music Recommendation* paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J52bumymOZ16",
        "colab_type": "text"
      },
      "source": [
        "## **Creating the data**\n",
        "\n",
        "\n",
        "*   Determine the number of users to use\n",
        "*   Get all songs' ratings for those users\n",
        "*   Consturct an interaction matrix\n",
        "*   Create a dataframe of triplets: user id, postive item id, negative item id\n",
        "*   create a N triplet for the same user (N = triplet_per_user)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SAgsJWT8ePu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def exsists_spectrogram(song_7did):\n",
        "  return os.path.exists('/content/drive/My Drive/RS project/spectrograms/' + str(song_7did) + '.clip.npy')\n",
        "\n",
        "def split_songs(song_7dids):\n",
        "  train, test  = train_test_split(song_7dids, test_size=0.1, random_state=1)\n",
        "  return train, test\n",
        "\n",
        "\n",
        "def get_interactions(subset_df, subset_users, subset_songs, relevant_song_ids):\n",
        "  interactions = []\n",
        "  for user_id in subset_users:\n",
        "    song_empty_onehot = np.zeros(len(subset_songs))\n",
        "    users_songs = subset_df.loc[subset_df['user_id'] == user_id]\n",
        "    for index, row in users_songs.iterrows():\n",
        "      if row['song_id'] in relevant_song_ids:\n",
        "        song_index = subset_songs.index(row['song_id'])\n",
        "        song_empty_onehot[song_index] = row['listenings']\n",
        "    interactions.append([song_empty_onehot])\n",
        "  return interactions\n",
        "\n",
        "def get_triplets(subset_users, triplets_per_user, interactions, dump_file_path):\n",
        "  triplets_dict = {}\n",
        "  triplets_counter = 0\n",
        "  for user_index in range(len(subset_users)):\n",
        "    for i in range(triplets_per_user):\n",
        "      users_interactions = interactions[user_index]\n",
        "      positive_users_indices = np.argwhere(np.array(users_interactions) > 0)\n",
        "      negative_user_indices = np.argwhere(np.array(users_interactions) == 0)\n",
        "\n",
        "      if positive_users_indices.shape[0] == 0 or negative_user_indices.shape[0] == 0:\n",
        "        continue\n",
        "\n",
        "      random_positive_index = positive_users_indices[np.random.randint(len(positive_users_indices))][1]\n",
        "      random_negative_index = negative_user_indices[np.random.randint(len(negative_user_indices))][1]\n",
        "      positive_song_id = subset_songs[random_positive_index]\n",
        "      negative_song_id = subset_songs[random_negative_index]\n",
        "      triplets_dict[triplets_counter] = [user_index, positive_song_id, negative_song_id]\n",
        "      triplets_counter += 1\n",
        "\n",
        "  triplets_df = pd.DataFrame.from_dict(triplets_dict, orient='index')\n",
        "  triplets_df.columns = ['user_index', 'positive_song_id', 'negative_song_id']\n",
        "\n",
        "\n",
        "  # clean df - get only rows with songs that have calculated spectrogram\n",
        "  triplets_df = triplets_df[triplets_df['positive_song_id'].apply(exsists_spectrogram)]\n",
        "  triplets_df = triplets_df[triplets_df['negative_song_id'].apply(exsists_spectrogram)]\n",
        "\n",
        "  # dump\n",
        "  pickle.dump(triplets_df, open(dump_file_path, 'wb'))\n",
        "\n",
        "def create_data(num_users = 200):\n",
        "  # read users history from file\n",
        "  history = pd.read_csv('/content/drive/My Drive/RS project/10000.txt', delimiter='\\t', header=None)\n",
        "  history.columns = ['user_id', 'song_id', 'listenings']\n",
        "\n",
        "  echonest_id_to_MSD_id = pickle.load(open('/content/drive/My Drive/RS project/echonest_id_to_MSD_id_unix.pkl', 'rb'))\n",
        "  MSD_id_to_7D_id_unix = pickle.load(open('/content/drive/My Drive/RS project/MSD_id_to_7D_id_unix.pkl', 'rb'))\n",
        "  history['song_id'] = history['song_id'].apply(lambda x: MSD_id_to_7D_id_unix[echonest_id_to_MSD_id[x]])\n",
        "\n",
        "  # get subset of num_users users\n",
        "  all_users = history['user_id'].unique()\n",
        "  subset_users = all_users[:num_users]\n",
        "  subset_df = history.loc[history['user_id'].isin(subset_users)]\n",
        "  subset_songs = list(subset_df['song_id'].unique())\n",
        "\n",
        "  return subset_df, subset_users, subset_songs\n",
        "\n",
        "def split_data(subset_df, subset_users, subset_songs, triplets_per_user = 20):\n",
        "  train, test = split_songs(subset_songs)\n",
        "\n",
        "\n",
        "  # create interactions matrices\n",
        "  train_interactions = get_interactions(subset_df, subset_users, subset_songs, train)\n",
        "  test_interactions = get_interactions(subset_df, subset_users, subset_songs, test)\n",
        "\n",
        "  # create triplets - triplets_per_user triplets per user\n",
        "  get_triplets(subset_users, triplets_per_user, train_interactions, '/content/drive/My Drive/RS project/train_triplets_df.pkl')\n",
        "  get_triplets(subset_users, triplets_per_user, testn_interactions, '/content/drive/My Drive/RS project/test_triplets_df.pkl')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqMjZLeQ8Lj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "  train =  pickle.load(open('/content/drive/My Drive/RS project/train_triplets_df.pkl', 'rb'))\n",
        "  test =  pickle.load(open('/content/drive/My Drive/RS project/test_triplets_df.pkl', 'rb'))\n",
        "  return train, test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ3opYgW8Xls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subset_df, subset_users, subset_songs = create_data()\n",
        "split_data(subset_df, subset_users, subset_songs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsSFZZrvo3QE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpJuk9_CPc1z",
        "colab_type": "text"
      },
      "source": [
        "## **Get songs' spectrograms**\n",
        "\n",
        "\n",
        "*   Spectrograms are created using mp3s_to_mel.py script from [this project](https://github.com/jongpillee/deep-content-user).\n",
        "*   Each spectrogram is a numpy array of the shape (frequency_bins, timestamps)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16doKXJcRRs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_spectrogram(song_7did, length = 1000, mean = 0.2262, std = 0.2579): \n",
        "  file_path = '/content/drive/My Drive/RS project/spectrograms/' + song_7did + '.clip.npy'\n",
        "  spectrogram = np.load(file_path).T\n",
        "\n",
        "  # fit spectrogram to the given length\n",
        "  # if spectrogram is too short, repeat the melody until length is reached\n",
        "  while spectrogram.shape[0] < length:\n",
        "    spectrogram = np.tile(spectrogram,(2,1))\n",
        "  # cut the spectrogram to fit length exactly\n",
        "  spectrogram = spectrogram[:length]\n",
        "\n",
        "  # normalize spectrogram\n",
        "  spectrogram -= mean\n",
        "  spectrogram /= std\n",
        "\n",
        "  spec_len = spectrogram.shape[0]\n",
        "  start_spec = np.random.randint(spec_len-130)\n",
        "  spectrogram = spectrogram[start_spec:]\n",
        "  if spectrogram.shape[0] < spec_len:\n",
        "      spectrogram = np.tile(spectrogram,(100,1))\n",
        "      spectrogram = spectrogram[:spec_len]\n",
        "\n",
        "  return spectrogram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rvaXTfeQAWx",
        "colab_type": "text"
      },
      "source": [
        "## **Create data generator**\n",
        "\n",
        "*   The output of the generator is of the form: x = the triplet [user_index, pos_spectrogram, neg_spectrogram], y = [1,0] (meaning that the first item should be classified as positive)\n",
        "*   Each generator step outputs a batch (of size batch_size) of the described above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qXR-2RYPipw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  create  generator\n",
        "# step output: user_index, pos_spectrogram, neg_spectrogram, [1,0]\n",
        "class Generator(Sequence):\n",
        "\n",
        "    def __init__(self, df, batch_size):\n",
        "        self.df = df\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.df) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_df = self.df[idx * self.batch_size:(idx + 1) *\n",
        "        self.batch_size]\n",
        "\n",
        "        user_index_batch = []\n",
        "        pos_spectrograms_batch = []\n",
        "        neg_spectrograms_batch = []\n",
        "        y_batch = []\n",
        "\n",
        "        for index, row in batch_df.iterrows():\n",
        "          user_index_batch.append(row['user_index'])\n",
        "          pos_spectrograms_batch.append(get_spectrogram(row['positive_song_id']))\n",
        "          neg_spectrograms_batch.append(get_spectrogram(row['negative_song_id']))\n",
        "          y_batch.append([1,0])\n",
        "\n",
        "        user_index_batch = np.asarray(user_index_batch)\n",
        "        pos_spectrograms_batch = np.asarray(pos_spectrograms_batch)\n",
        "        neg_spectrograms_batch = np.asarray(neg_spectrograms_batch)\n",
        "        y_batch = np.asarray(y_batch)\n",
        "\n",
        "        return [user_index_batch, pos_spectrograms_batch, neg_spectrograms_batch], y_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsD7jR5wQscb",
        "colab_type": "text"
      },
      "source": [
        "## **Define the Model class**\n",
        "\n",
        "The model is consturcted of three sub models:\n",
        "*   User (anchor) model - which learns the users' embeddings\n",
        "*   Positive item model - which learns the positive items' embeddings\n",
        "*   Negative item model - which learns the negative items' embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84lZFYmOt8S8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hinge_loss(y_true,y_pred):\n",
        "    # hinge loss\n",
        "    y_pos = y_pred[:,:1]\n",
        "    y_neg = y_pred[:,1:]\n",
        "    loss = K.sum(K.maximum(0., 0.2 - y_pos + y_neg))\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMtGV1KzSRXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model:\n",
        "  def __init__(self, num_users, num_songs, weights_path, spectrogram_length = 1000, freq_bins = 128,dim_embedding = 300, lr = 0.2, lrdecay = 1e-6):\n",
        "    self.num_users = num_users\n",
        "    self.num_songs = num_songs\n",
        "    self.dim_embedding = dim_embedding\n",
        "    self.weights_path = weights_path\n",
        "\n",
        "    self.callbacks = [ModelCheckpoint(\n",
        "    weights_path, monitor='val_loss', verbose=0, save_best_only=True,\n",
        "    save_weights_only=True), \n",
        "    TensorBoard(log_dir = '/content/drive/My Drive/RS project/logs_original_model', histogram_freq=1)]\n",
        "\n",
        "    self.user_index_input = Input(shape=(1,))\n",
        "    self.pos_item_input = Input(shape=(spectrogram_length, freq_bins))\n",
        "    self.neg_item_input = Input(shape=(spectrogram_length, freq_bins))\n",
        "\n",
        "    # user model - one hot\n",
        "    user_dict = Embedding(num_users, 300, input_length=1)\n",
        "    user_flat = Flatten()\n",
        "    user_activ1 = Activation('relu')\n",
        "    user_dense2 = Dense(300)\n",
        "    user_activ2 = Activation('relu')\n",
        "    user_sem = Dense(self.dim_embedding,activation='linear')\n",
        "    \n",
        "\n",
        "    # anchor user\n",
        "    anchor_user_dense1 =  user_dict(self.user_index_input)\n",
        "    anchor_user_flat = user_flat(anchor_user_dense1)\n",
        "    anchor_user_activ1 = user_activ1(anchor_user_flat)\n",
        "    anchor_user_dense2 = user_dense2(anchor_user_activ1)\n",
        "    anchor_user_activ2 = user_activ2(anchor_user_dense2)\n",
        "    self.anchor_user_sem = user_sem(anchor_user_activ2)\n",
        "\n",
        "    # item model **audio**\n",
        "    conv1 = Conv1D(128,4,padding='same',use_bias=True,kernel_initializer='he_uniform')\n",
        "    activ1 = Activation('relu')\n",
        "    MP1 = MaxPool1D(pool_size=4)\n",
        "    conv2 = Conv1D(self.dim_embedding,4,padding='same',use_bias=True,kernel_initializer='he_uniform')\n",
        "    activ2 = Activation('relu')\n",
        "    MP2 = MaxPool1D(pool_size=4)\n",
        "    conv3 = Conv1D(self.dim_embedding,4,padding='same',use_bias=True,kernel_initializer='he_uniform')\n",
        "    activ3 = Activation('relu')\n",
        "    MP3 = MaxPool1D(pool_size=4)\n",
        "    conv4 = Conv1D(self.dim_embedding,2,padding='same',use_bias=True,kernel_initializer='he_uniform')\n",
        "    activ4 = Activation('relu')\n",
        "    MP4 = MaxPool1D(pool_size=2)\n",
        "    conv5 = Conv1D(self.dim_embedding,1,padding='same',use_bias=True,kernel_initializer='he_uniform')\n",
        "    activ5 = Activation('relu')\n",
        "\n",
        "    avg_pool = GlobalAvgPool1D()\n",
        "    item_sem = Dense(self.dim_embedding,activation='linear')\n",
        "\n",
        "    # pos item\n",
        "    pos_item_conv1 = conv1(self.pos_item_input)\n",
        "    pos_item_activ1 = activ1(pos_item_conv1)\n",
        "    pos_item_MP1 = MP1(pos_item_activ1)\n",
        "    pos_item_conv2 = conv2(pos_item_MP1)\n",
        "    pos_item_activ2 = activ2(pos_item_conv2)\n",
        "    pos_item_MP2 = MP2(pos_item_activ2)\n",
        "    pos_item_conv3 = conv3(pos_item_MP2)\n",
        "    pos_item_activ3 = activ3(pos_item_conv3)\n",
        "    pos_item_MP3 = MP3(pos_item_activ3)\n",
        "    pos_item_conv4 = conv4(pos_item_MP3)\n",
        "    pos_item_activ4 = activ4(pos_item_conv4)\n",
        "    pos_item_MP4 = MP4(pos_item_activ4)\n",
        "    pos_item_conv5 = conv5(pos_item_MP4)\n",
        "    pos_item_activ5 = activ5(pos_item_conv5)\n",
        "    pos_item_avg = avg_pool(pos_item_activ5)\n",
        "    self.pos_item_sem = item_sem(pos_item_avg)\n",
        "\n",
        "    # neg item\n",
        "    neg_item_bn1 = conv1(self.neg_item_input)\n",
        "    neg_item_activ1 = activ1(neg_item_bn1)\n",
        "    neg_item_MP1 = MP1(neg_item_activ1)\n",
        "    neg_item_bn2 = conv2(neg_item_MP1)\n",
        "    neg_item_activ2 = activ2(neg_item_bn2)\n",
        "    neg_item_MP2 = MP2(neg_item_activ2)\n",
        "    neg_item_bn3 = conv3(neg_item_MP2)\n",
        "    neg_item_activ3 = activ3(neg_item_bn3)\n",
        "    neg_item_MP3 = MP3(neg_item_activ3)\n",
        "    neg_item_bn4 = conv4(neg_item_MP3)\n",
        "    neg_item_activ4 = activ4(neg_item_bn4)\n",
        "    neg_item_MP4 = MP4(neg_item_activ4)\n",
        "    neg_item_bn5 = conv5(neg_item_MP4)\n",
        "    neg_item_activ5 = activ5(neg_item_bn5)\n",
        "    neg_item_avg = avg_pool(neg_item_activ5)\n",
        "    self.neg_item_sem = item_sem(neg_item_avg)\n",
        "\n",
        "    # when using normalize=True, norm_a = a/|a|. Thus, for cosine similarity we can use dot product.\n",
        "    v_p = dot([self.anchor_user_sem, self.pos_item_sem], axes = 1, normalize = True)\n",
        "    v_ns = dot([self.anchor_user_sem, self.neg_item_sem], axes = 1, normalize = True)\n",
        "\n",
        "    prob = concatenate([v_p] + [v_ns])\n",
        "    output = Activation('linear', name='output')(prob)\n",
        "\n",
        "    self.full_model = keras.models.Model(inputs = [self.user_index_input, self.pos_item_input, self.neg_item_input], outputs = output)\n",
        "    sgd = SGD(lr=lr,decay=lrdecay,momentum=0.9,nesterov=True)\n",
        "    self.full_model.compile(optimizer=sgd,loss=hinge_loss,metrics=['accuracy'])\n",
        "\n",
        "    self.audio_model = keras.models.Model(inputs = self.pos_item_input, outputs = self.pos_item_sem)\n",
        "    self.audio_model.compile(optimizer=sgd,loss=hinge_loss,metrics=['accuracy'])\n",
        "\n",
        "    self.user_model = keras.models.Model(inputs = self.user_index_input, outputs = self.anchor_user_sem)\n",
        "    self.user_model.compile(optimizer=sgd,loss=hinge_loss,metrics=['accuracy'])\n",
        "\n",
        "  def fit(self, train_generator, epochs):\n",
        "    self.full_model.fit(x = train_generator, epochs=epochs, callbacks = self.callbacks)\n",
        "\n",
        "  def load(self):\n",
        "    self.full_model.load_weights(self.weights_path)\n",
        "\n",
        "  def encode(self, items, item_embedding_path, user_embedding_path):\n",
        "    # encode items and save to files\n",
        "    item_embedding = np.zeros((self.num_songs,self.dim_embedding))\n",
        "    for index, song_7did in enumerate(items):\n",
        "      if not os.path.exists('/content/drive/My Drive/RS project/spectrograms/' + song_7did + '.clip.npy'):\n",
        "        continue\n",
        "      spectrogram = get_spectrogram(song_7did)\n",
        "      predicted = self.audio_model.predict(np.expand_dims(spectrogram, axis=0))\n",
        "      item_embedding[index] = np.mean(predicted,axis=0)\n",
        "    np.save(item_embedding_path ,item_embedding)\n",
        "\n",
        "    # encode users\n",
        "    user_embedding = self.user_model.predict(np.arange(self.num_users))\n",
        "    np.save(user_embedding_path, user_embedding)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHWwIz9_SbHc",
        "colab_type": "text"
      },
      "source": [
        " ## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vco9RwMScZVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_songs = len(subset_songs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiYI-ZVqSagZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# init the model\n",
        "model = Model(num_users = 200, num_songs = num_songs, weights_path = '/content/drive/My Drive/RS project/model_weights.h5')\n",
        "model.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf60JEjtxrT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# init the generators\n",
        "train_generator = Generator(train, batch_size=5)\n",
        "\n",
        "model.fit(train_generator, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMyObCPiwoSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %tensorboard --logdir '/content/drive/My Drive/RS project/logs_original_model'"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrIvXzi9SoR9",
        "colab_type": "text"
      },
      "source": [
        " ## **Saving the embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdkCLm9SIzzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "item_embedding_path = '/content/drive/My Drive/RS project/item_embedding.npy'\n",
        "user_embedding_path = '/content/drive/My Drive/RS project/user_embedding.npy'\n",
        "model.encode(subset_songs, item_embedding_path, user_embedding_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0x6j1a5Sxwq",
        "colab_type": "text"
      },
      "source": [
        " ## **Evaluation**\n",
        " \n",
        "\n",
        "*   Getting the original interaction matrix\n",
        "*   Getting the predicted interaction matrix by applying cosine similarity between the users' and the items' embeddings\n",
        "*   Computing avarage AUC of the original and the predicted interaction matrices\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv885tFXToIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_original_interactions(subset_df, subset_users, subset_songs):\n",
        "  interactions = np.array(get_interactions(subset_df, subset_users, subset_songs, subset_songs))\n",
        "  # convert to binary\n",
        "  interactions[interactions >= 1] = 1\n",
        "  interactions = interactions.reshape(len(subset_users), len(subset_songs))\n",
        "  return interactions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK26gYTdWA98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predicted_interactions(item_embedding_path, user_embedding_path, num_users = 200):\n",
        "  item_embedding = np.load(item_embedding_path)\n",
        "  user_embedding = np.load(user_embedding_path)\n",
        "  interactions = cosine_similarity(item_embedding, user_embedding)\n",
        "  interactions = np.array(interactions)\n",
        "  interactions = interactions.T\n",
        "  return interactions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PEZnP3mWkIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_auc_score(original_interactions, predicted_interactions, num_users = 200):\n",
        "  users_auc = []\n",
        "  for user_index in range(num_users):\n",
        "    try:\n",
        "      user_auc = metrics.roc_auc_score(original_interactions[user_index], predicted_interactions[user_index], multi_class='ovo')\n",
        "      users_auc.append(user_auc)\n",
        "    except ValueError:\n",
        "      pass\n",
        "  return statistics.mean(users_auc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CeqdeqMpOLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_pop_auc_score(original_interactions, pop, num_users = 200):\n",
        "  users_auc = []\n",
        "  for user_index in range(num_users):\n",
        "    try:\n",
        "      user_auc = metrics.roc_auc_score(original_interactions[user_index], pop, multi_class='ovo')\n",
        "      users_auc.append(user_auc)\n",
        "    except ValueError:\n",
        "      pass\n",
        "  return statistics.mean(users_auc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e31wTE-WbHzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_songs = list(set(list(train.positive_song_id.unique()) + list(train.negative_song_id.unique())))\n",
        "train_indices = [subset_songs.index(song_id) for song_id in train_songs]\n",
        "\n",
        "\n",
        "test_songs = list(set(list(test.positive_song_id.unique()) + list(test.negative_song_id.unique())))\n",
        "test_indices = [subset_songs.index(song_id) for song_id in test_songs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbewAv0rYed_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "item_embedding_path = '/content/drive/My Drive/RS project/item_embedding.npy'\n",
        "user_embedding_path = '/content/drive/My Drive/RS project/user_embedding.npy'\n",
        "original_interactions = get_original_interactions(subset_df, subset_users, subset_songs)\n",
        "predicted_interactions = get_predicted_interactions(item_embedding_path, user_embedding_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_7LYjlqVvr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auc = get_auc_score(original_interactions[:,test_indices], predicted_interactions[:,test_indices])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlcIVCGEYGt-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5741dc5b-9cd0-4540-f469-2e8a4a713f0f"
      },
      "source": [
        "auc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7147152156031262"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMV__LhiqoUJ",
        "colab_type": "text"
      },
      "source": [
        " ### **Comparing to popularity based recommendation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDWXRhSWnmuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Popular items\n",
        "pop_items = np.sum(original_interactions[:,test_indices],axis=0)\n",
        "auc = get_pop_auc_score(original_interactions[:,test_indices], pop_items, num_users = 200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAXK7GN-qkuz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61107f02-f135-4b52-bc3a-dff8bf1ecea8"
      },
      "source": [
        "auc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6472221541205211"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Uq8bcaPLUQkn"
      },
      "source": [
        "# **Modified Model**\n",
        "A modified model, which combines songs' metadata as items' content, in addition to the songs' spectrograms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HMYThl_cUQko"
      },
      "source": [
        "## **Creating additional data**\n",
        "Creating a dataframe whcih contains songs' metadata\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wjxQDYx4UQkp",
        "colab": {}
      },
      "source": [
        "def create_metadata(songs, dump_file_path = '/content/drive/My Drive/RS project/metadata_df.pkl'):\n",
        "\n",
        "  MSD_id_to_7D_id_unix = pickle.load(open('/content/drive/My Drive/RS project/MSD_id_to_7D_id_unix.pkl', 'rb'))\n",
        "  metadata_df = pd.read_csv('/content/drive/My Drive/RS project/echonest_data.csv')\n",
        "  metadata_df['song_7did'] = metadata_df['track_id'].apply(lambda x: MSD_id_to_7D_id_unix[x])\n",
        "\n",
        "  metadata_dict = {}\n",
        "  metadata_counter = 0\n",
        "\n",
        "  for song_7did in songs:\n",
        "    row = metadata_df[metadata_df['song_7did'] == song_7did]\n",
        "    metadata_dict[metadata_counter] = {'song_7did' : song_7did}\n",
        "    if row.shape[0] > 0:\n",
        "      metadata_dict[metadata_counter]['artist_name'] = row.iloc[0]['artist_name']\n",
        "      metadata_dict[metadata_counter]['tempo'] = row.iloc[0]['tempo']\n",
        "      metadata_dict[metadata_counter]['loudness'] = row.iloc[0]['loudness']\n",
        "      metadata_dict[metadata_counter]['mode'] = row.iloc[0]['mode']\n",
        "\n",
        "    metadata_counter += 1\n",
        "  \n",
        "  metadata_df = pd.DataFrame.from_dict(metadata_dict, orient='index')\n",
        "\n",
        "  # normalize tempo and loudness between 0 and 1\n",
        "  metadata_df['tempo_norm'] = (metadata_df['tempo']-metadata_df['tempo'].min())/(metadata_df['tempo'].max()-metadata_df['tempo'].min())\n",
        "  metadata_df['loudness_norm'] = (metadata_df['loudness']-metadata_df['loudness'].min())/(metadata_df['loudness'].max()-metadata_df['loudness'].min())\n",
        "  metadata_df = metadata_df.drop(['tempo', 'loudness'], axis=1)\n",
        "  metadata_df = metadata_df.rename(columns={\"tempo_norm\": \"tempo\", \"loudness_norm\": \"loudness\"})\n",
        "\n",
        "  metadata_df = metadata_df.dropna()\n",
        "\n",
        "  pickle.dump(metadata_df, open(dump_file_path, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o5czelDQUQkr",
        "colab": {}
      },
      "source": [
        "def load_metadata(dump_file_path = '/content/drive/My Drive/RS project/metadata_df.pkl'):\n",
        "  return pickle.load(open(dump_file_path, 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nbvmnAxsUQkv",
        "colab": {}
      },
      "source": [
        "# create_metadata(subset_songs)\n",
        "metadata_df = load_metadata()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpCMAVimImn-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "3cba832f-5de5-4452-d69a-a3d7ae02f12a"
      },
      "source": [
        "metadata_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>song_7did</th>\n",
              "      <th>artist_name</th>\n",
              "      <th>mode</th>\n",
              "      <th>tempo</th>\n",
              "      <th>loudness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2093263</td>\n",
              "      <td>Jack Johnson</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.476799</td>\n",
              "      <td>0.566081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2631392</td>\n",
              "      <td>Paco De Lucia</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.741553</td>\n",
              "      <td>0.828729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1356697</td>\n",
              "      <td>Kanye West</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.532296</td>\n",
              "      <td>0.793565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2424087</td>\n",
              "      <td>Jack Johnson</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.468307</td>\n",
              "      <td>0.666338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3360473</td>\n",
              "      <td>Foo Fighters</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.522993</td>\n",
              "      <td>0.919507</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  song_7did    artist_name  mode     tempo  loudness\n",
              "0   2093263   Jack Johnson   1.0  0.476799  0.566081\n",
              "1   2631392  Paco De Lucia   0.0  0.741553  0.828729\n",
              "2   1356697     Kanye West   1.0  0.532296  0.793565\n",
              "3   2424087   Jack Johnson   1.0  0.468307  0.666338\n",
              "4   3360473   Foo Fighters   0.0  0.522993  0.919507"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TzQ1kcgeUQky"
      },
      "source": [
        "## **Modify data generator**\n",
        "\n",
        "*   The x part of the genrator's outpus should contain songs' metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LxFOkgDBUQkz",
        "colab": {}
      },
      "source": [
        "#  create  generator\n",
        "# step output: user_index, pos_spectrogram, neg_spectrogram, [1,0]\n",
        "class ModifiedGenerator(Sequence):\n",
        "\n",
        "    def __init__(self, df, metadata_df, batch_size):\n",
        "        self.df = df\n",
        "        self.metadata_df = metadata_df\n",
        "        self.artists = list(metadata_df.artist_name.unique())\n",
        "        self.batch_size = batch_size\n",
        "        self.metadata_length = len(self.artists) + 3\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.df) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_df = self.df[idx * self.batch_size:(idx + 1) *\n",
        "        self.batch_size]\n",
        "\n",
        "        user_index_batch = []\n",
        "        pos_spectrograms_batch = []\n",
        "        pos_metdata_batch = []\n",
        "        neg_spectrograms_batch = []\n",
        "        neg_metdata_batch = []\n",
        "        y_batch = []\n",
        "\n",
        "        for index, row in batch_df.iterrows():\n",
        "          # get anchor user\n",
        "          user_index_batch.append(row['user_index'])\n",
        "\n",
        "          # get positive item\n",
        "          pos_song_7did = row['positive_song_id']\n",
        "          # get spectrogram\n",
        "          pos_spectrograms_batch.append(get_spectrogram(pos_song_7did))\n",
        "          # get metadata\n",
        "          # if no metadata is available\n",
        "          if self.metadata_df[self.metadata_df['song_7did'] == pos_song_7did].shape[0] == 0:\n",
        "            pos_metdata_batch.append(np.zeros(self.metadata_length))\n",
        "          else:\n",
        "            pos_metdata = self.get_metadata(pos_song_7did)\n",
        "            pos_metdata_batch.append(pos_metdata)\n",
        "          \n",
        "          # get negative item\n",
        "          neg_song_7did = row['negative_song_id']\n",
        "          # get spectrogram\n",
        "          neg_spectrograms_batch.append(get_spectrogram(neg_song_7did))\n",
        "          # get metadata\n",
        "          if self.metadata_df[self.metadata_df['song_7did'] == neg_song_7did].shape[0] == 0:\n",
        "            neg_metdata_batch.append(np.zeros(self.metadata_length))\n",
        "          else:\n",
        "            neg_metdata = self.get_metadata(neg_song_7did)\n",
        "            neg_metdata_batch.append(neg_metdata)\n",
        "\n",
        "          # append y\n",
        "          y_batch.append([1,0])\n",
        "\n",
        "\n",
        "        return  ({'user_index_input': np.array(user_index_batch), 'pos_item_input': np.array(pos_spectrograms_batch),\n",
        "                  'pos_item_metadata_input': np.array(pos_metdata_batch), 'neg_item_input': np.array(neg_spectrograms_batch),\n",
        "                  'neg_item_metadata_input': np.array(neg_metdata_batch)\n",
        "                  }, {'output': np.array(y_batch)})\n",
        "\n",
        "    def to_categorical(self, artist_name):\n",
        "      num_artists = len(self.artists)\n",
        "      one_hot = np.zeros(num_artists)\n",
        "      artists_index = self.artists.index(artist_name)\n",
        "      one_hot[artists_index] = 1\n",
        "      return list(one_hot)\n",
        "\n",
        "    def get_metadata(self, song_7did):\n",
        "      metadata_row = self.metadata_df[self.metadata_df['song_7did'] == song_7did]\n",
        "      metadata_row = metadata_row.iloc[0]\n",
        "      artist_name = metadata_row['artist_name']\n",
        "      artist_one_hot = self.to_categorical(artist_name)\n",
        "      tempo = [metadata_row['tempo']]\n",
        "      loudness = [metadata_row['loudness']]\n",
        "      mode = [metadata_row['mode']]\n",
        "\n",
        "      # concat into one vector\n",
        "      return np.array(artist_one_hot  + tempo + loudness + mode)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WpHpNaehUQk0"
      },
      "source": [
        "## **Modify the model**\n",
        "\n",
        "Expand the positive and negative models to include a sub-model which deals with metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VBkXEYd-UQk1",
        "colab": {}
      },
      "source": [
        "class ModifiedModel:\n",
        "  def __init__(self, num_users, num_songs, weights_path, metadata_size, generator, spectrogram_length = 1000, freq_bins = 128,dim_embedding = 300, lr = 0.2, lrdecay = 1e-6):\n",
        "    self.num_users = num_users\n",
        "    self.num_songs = num_songs\n",
        "    self.dim_embedding = dim_embedding\n",
        "    self.metadata_size = metadata_size\n",
        "    self.weights_path = weights_path\n",
        "    self.generator = generator\n",
        "\n",
        "    self.callbacks = [ModelCheckpoint(\n",
        "    weights_path, monitor='val_loss', verbose=0, save_best_only=True,\n",
        "    save_weights_only=True), \n",
        "    TensorBoard(log_dir = '/content/drive/My Drive/RS project/logs_midified_model', histogram_freq=1)]\n",
        "\n",
        "    self.user_index_input = Input(shape=(1,), name='user_index_input')\n",
        "    self.pos_item_input = Input(shape=(spectrogram_length, freq_bins), name='pos_item_input')\n",
        "    self.pos_item_metadata_input = Input(shape=(metadata_size,), name='pos_item_metadata_input')\n",
        "    self.neg_item_input = Input(shape=(spectrogram_length, freq_bins), name='neg_item_input')\n",
        "    self.neg_item_metadata_input = Input(shape=(metadata_size,), name='neg_item_metadata_input')\n",
        "\n",
        "\n",
        "    # user model - one hot\n",
        "    user_dict = Embedding(num_users, 300, input_length=1)\n",
        "    user_flat = Flatten()\n",
        "    user_activ1 = Activation('relu')\n",
        "    user_dense2 = Dense(300)\n",
        "    user_activ2 = Activation('relu')\n",
        "    user_sem = Dense(self.dim_embedding,activation='linear')\n",
        "\n",
        "    # anchor user\n",
        "    anchor_user_dense1 =  user_dict(self.user_index_input)\n",
        "    anchor_user_flat = user_flat(anchor_user_dense1)\n",
        "    anchor_user_activ1 = user_activ1(anchor_user_flat)\n",
        "    anchor_user_dense2 = user_dense2(anchor_user_activ1)\n",
        "    anchor_user_activ2 = user_activ2(anchor_user_dense2)\n",
        "    self.anchor_user_sem = user_sem(anchor_user_activ2)\n",
        "\n",
        "    # item model **audio**\n",
        "    conv1 = Conv1D(128,4,padding='same',use_bias=True,kernel_initializer='he_uniform')\n",
        "    activ1 = Activation('relu')\n",
        "    MP1 = MaxPool1D(pool_size=4)\n",
        "    conv2 = Conv1D(self.dim_embedding,4,padding='same',use_bias=True,kernel_initializer='he_uniform')\n",
        "    activ2 = Activation('relu')\n",
        "    MP2 = MaxPool1D(pool_size=4)\n",
        "    conv3 = Conv1D(self.dim_embedding,4,padding='same',use_bias=True,kernel_initializer='he_uniform')\n",
        "    activ3 = Activation('relu')\n",
        "    MP3 = MaxPool1D(pool_size=4)\n",
        "    conv4 = Conv1D(self.dim_embedding,2,padding='same',use_bias=True,kernel_initializer='he_uniform')\n",
        "    activ4 = Activation('relu')\n",
        "    MP4 = MaxPool1D(pool_size=2)\n",
        "    conv5 = Conv1D(self.dim_embedding,1,padding='same',use_bias=True,kernel_initializer='he_uniform')\n",
        "    activ5 = Activation('relu')\n",
        "\n",
        "    avg_pool = GlobalAvgPool1D()\n",
        "    item_sem = Dense(self.dim_embedding,activation='linear')\n",
        "\n",
        "    # pos item\n",
        "    pos_item_conv1 = conv1(self.pos_item_input)\n",
        "    pos_item_activ1 = activ1(pos_item_conv1)\n",
        "    pos_item_MP1 = MP1(pos_item_activ1)\n",
        "    pos_item_conv2 = conv2(pos_item_MP1)\n",
        "    pos_item_activ2 = activ2(pos_item_conv2)\n",
        "    pos_item_MP2 = MP2(pos_item_activ2)\n",
        "    pos_item_conv3 = conv3(pos_item_MP2)\n",
        "    pos_item_activ3 = activ3(pos_item_conv3)\n",
        "    pos_item_MP3 = MP3(pos_item_activ3)\n",
        "    pos_item_conv4 = conv4(pos_item_MP3)\n",
        "    pos_item_activ4 = activ4(pos_item_conv4)\n",
        "    pos_item_MP4 = MP4(pos_item_activ4)\n",
        "    pos_item_conv5 = conv5(pos_item_MP4)\n",
        "    pos_item_activ5 = activ5(pos_item_conv5)\n",
        "    pos_item_avg = avg_pool(pos_item_activ5)\n",
        "    pos_spec_model_output = item_sem(pos_item_avg)\n",
        "\n",
        "    # neg item\n",
        "    neg_item_bn1 = conv1(self.neg_item_input)\n",
        "    neg_item_activ1 = activ1(neg_item_bn1)\n",
        "    neg_item_MP1 = MP1(neg_item_activ1)\n",
        "    neg_item_bn2 = conv2(neg_item_MP1)\n",
        "    neg_item_activ2 = activ2(neg_item_bn2)\n",
        "    neg_item_MP2 = MP2(neg_item_activ2)\n",
        "    neg_item_bn3 = conv3(neg_item_MP2)\n",
        "    neg_item_activ3 = activ3(neg_item_bn3)\n",
        "    neg_item_MP3 = MP3(neg_item_activ3)\n",
        "    neg_item_bn4 = conv4(neg_item_MP3)\n",
        "    neg_item_activ4 = activ4(neg_item_bn4)\n",
        "    neg_item_MP4 = MP4(neg_item_activ4)\n",
        "    neg_item_bn5 = conv5(neg_item_MP4)\n",
        "    neg_item_activ5 = activ5(neg_item_bn5)\n",
        "    neg_item_avg = avg_pool(neg_item_activ5)\n",
        "    neg_spec_model_output = item_sem(neg_item_avg)\n",
        "\n",
        "    # item model **metadata**\n",
        "    metadata_dense_1 = Dense(300, activation='relu')\n",
        "    metadata_batch_norm_1 = BatchNormalization()\n",
        "    metadata_batch_tanh_1 = Activation('tanh')\n",
        "    metadata_batch_dropout_1 = Dropout(0.5)\n",
        "\n",
        "    metadata_dense_2 = Dense(200, activation='relu')\n",
        "    metadata_batch_norm_2 = BatchNormalization()\n",
        "    metadata_batch_tanh_2 = Activation('tanh')\n",
        "    metadata_batch_dropout_2 = Dropout(0.5)\n",
        "\n",
        "    metadata_dense_3 = Dense(150, activation='relu')\n",
        "    metadata_batch_norm_3 = BatchNormalization()\n",
        "    metadata_batch_tanh_3 = Activation('tanh')\n",
        "    metadata_batch_dropout_3 = Dropout(0.5)\n",
        "\n",
        "    metadata_dense_4 = Dense(50, activation='relu')\n",
        "    metadata_batch_norm_4 = BatchNormalization()\n",
        "    metadata_batch_softmex = Activation('softmax')\n",
        "\n",
        "\n",
        "\n",
        "    # pos item\n",
        "    pos_metadata_output_1 = metadata_dense_1(self.pos_item_metadata_input)\n",
        "    pos_metadata_output_2 = metadata_batch_norm_1(pos_metadata_output_1)\n",
        "    pos_metadata_output_3 = metadata_batch_tanh_1(pos_metadata_output_2)\n",
        "    pos_metadata_output_4 = metadata_batch_dropout_1(pos_metadata_output_3)\n",
        "\n",
        "    pos_metadata_output_5 = metadata_dense_2(pos_metadata_output_4)\n",
        "    pos_metadata_output_6 = metadata_batch_norm_2(pos_metadata_output_5)\n",
        "    pos_metadata_output_7 = metadata_batch_tanh_2(pos_metadata_output_6)\n",
        "    pos_metadata_output_8 = metadata_batch_dropout_2(pos_metadata_output_7)\n",
        "\n",
        "    pos_metadata_output_9 = metadata_dense_3(pos_metadata_output_8)\n",
        "    pos_metadata_output_10 = metadata_batch_norm_3(pos_metadata_output_9)\n",
        "    pos_metadata_output_11 = metadata_batch_tanh_3(pos_metadata_output_10)\n",
        "    pos_metadata_output_12 = metadata_batch_dropout_3(pos_metadata_output_11)\n",
        "\n",
        "    pos_metadata_output_13 = metadata_dense_4(pos_metadata_output_12)\n",
        "    pos_metadata_output_14 = metadata_batch_norm_4(pos_metadata_output_13)\n",
        "    pos_metadata_output = metadata_batch_softmex(pos_metadata_output_14)\n",
        " \n",
        "    # neg item\n",
        "    neg_metadata_output_1 = metadata_dense_1(self.neg_item_metadata_input)\n",
        "    neg_metadata_output_2 = metadata_batch_norm_1(neg_metadata_output_1)\n",
        "    neg_metadata_output_3 = metadata_batch_tanh_1(neg_metadata_output_2)\n",
        "    neg_metadata_output_4 = metadata_batch_dropout_1(neg_metadata_output_3)\n",
        "\n",
        "    neg_metadata_output_5 = metadata_dense_2(neg_metadata_output_4)\n",
        "    neg_metadata_output_6 = metadata_batch_norm_2(neg_metadata_output_5)\n",
        "    neg_metadata_output_7 = metadata_batch_tanh_2(neg_metadata_output_6)\n",
        "    neg_metadata_output_8 = metadata_batch_dropout_2(neg_metadata_output_7)\n",
        "\n",
        "    neg_metadata_output_9 = metadata_dense_3(neg_metadata_output_8)\n",
        "    neg_metadata_output_10 = metadata_batch_norm_3(neg_metadata_output_9)\n",
        "    neg_metadata_output_11 = metadata_batch_tanh_3(neg_metadata_output_10)\n",
        "    neg_metadata_output_12 = metadata_batch_dropout_3(neg_metadata_output_11)\n",
        "\n",
        "    neg_metadata_output_13 = metadata_dense_4(neg_metadata_output_12)\n",
        "    neg_metadata_output_14 = metadata_batch_norm_4(neg_metadata_output_13)\n",
        "    neg_metadata_output = metadata_batch_softmex(neg_metadata_output_14)\n",
        "\n",
        "    #combine spectrogram model output and metadata model output\n",
        "    concat_spec_metadata = Concatenate()\n",
        "    dense_concat = Dense(self.dim_embedding)\n",
        "\n",
        "    pos_concat = concat_spec_metadata([pos_spec_model_output, pos_metadata_output])\n",
        "    self.pos_combined = dense_concat(pos_concat)\n",
        "    neg_concat = concat_spec_metadata([neg_spec_model_output, neg_metadata_output])\n",
        "    self.neg_combined = dense_concat(neg_concat)\n",
        "\n",
        "    # compute cosine similarity \n",
        "    # when using normalize=True, norm_a = a/|a|. Thus, for cosine similarity we can use dot product.\n",
        "    v_p = dot([self.anchor_user_sem, self.pos_combined], axes = 1, normalize = True)\n",
        "    v_ns = dot([self.anchor_user_sem, self.neg_combined], axes = 1, normalize = True)\n",
        "\n",
        "    prob = concatenate([v_p] + [v_ns])\n",
        "    output = Activation('linear', name='output')(prob)\n",
        "\n",
        "    self.full_model = keras.models.Model(inputs = [self.user_index_input,\n",
        "                                                   self.pos_item_input, self.pos_item_metadata_input,\n",
        "                                                   self.neg_item_input, self.neg_item_metadata_input], outputs = output)\n",
        "    \n",
        "    \n",
        "    sgd = SGD(lr=lr,decay=lrdecay,momentum=0.9,nesterov=True)\n",
        "    self.full_model.compile(optimizer=sgd,loss=hinge_loss,metrics=['accuracy'])\n",
        "\n",
        "    self.audio_model = keras.models.Model(inputs = [self.pos_item_input, self.pos_item_metadata_input], outputs = self.pos_combined)\n",
        "    self.audio_model.compile(optimizer=sgd,loss=hinge_loss,metrics=['accuracy'])\n",
        "\n",
        "    self.user_model = keras.models.Model(inputs = self.user_index_input, outputs = self.anchor_user_sem)\n",
        "    self.user_model.compile(optimizer=sgd,loss=hinge_loss,metrics=['accuracy'])\n",
        "\n",
        "  def fit(self, train_generator, epochs):\n",
        "    self.full_model.fit(x = train_generator, epochs=epochs, callbacks = self.callbacks)\n",
        "  \n",
        "  def load(self):\n",
        "    self.full_model.load_weights(self.weights_path)\n",
        "\n",
        "  def encode(self, items, item_embedding_path, user_embedding_path):\n",
        "    # encode items and save to files\n",
        "    item_embedding = np.zeros((self.num_songs,self.dim_embedding))\n",
        "    for index, song_7did in enumerate(items):\n",
        "      if not os.path.exists('/content/drive/My Drive/RS project/spectrograms/' + song_7did + '.clip.npy'):\n",
        "        continue\n",
        "      if self.generator.metadata_df[self.generator.metadata_df['song_7did'] == song_7did].shape[0] == 0:\n",
        "        continue\n",
        "      spectrogram = get_spectrogram(song_7did)\n",
        "      metadata = self.generator.get_metadata(song_7did)\n",
        "      input = {'pos_item_input': np.array([spectrogram]),\n",
        "       'pos_item_metadata_input': np.array([metadata])\n",
        "      }\n",
        "      predicted = self.audio_model.predict(input)\n",
        "      item_embedding[index] = np.mean(predicted,axis=0)\n",
        "    np.save(item_embedding_path ,item_embedding)\n",
        "\n",
        "    # encode users\n",
        "    user_embedding = self.user_model.predict(np.arange(self.num_users))\n",
        "    np.save(user_embedding_path, user_embedding)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OLULlakjUQk2"
      },
      "source": [
        " ## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mmdR14FrUQk3",
        "colab": {}
      },
      "source": [
        "# define num_songs \n",
        "# users = triplets_df['user_index'].unique()\n",
        "# songs = set(list(triplets_df['positive_song_7did'].unique()) + list(triplets_df['negative_song_7did'].unique()))\n",
        "num_songs = len(subset_songs)\n",
        "artists = list(metadata_df.artist_name.unique())\n",
        "metadata_size = len(artists) + 3\n",
        "\n",
        "# init the generator \n",
        "train_generator = ModifiedGenerator(train, metadata_df, batch_size=5)\n",
        "\n",
        "\n",
        "# init the model\n",
        "model = ModifiedModel(num_users = 200, num_songs = num_songs, weights_path = '/content/drive/My Drive/RS project/modified_model_weights.h5', metadata_size = metadata_size, generator = train_generator)\n",
        "model.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vALX9WMRUQk5",
        "colab": {}
      },
      "source": [
        "# train\n",
        "model.fit(train_generator, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFhlgrC9xrwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %tensorboard --logdir '/content/drive/My Drive/RS project/logs_midified_model'"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EFXzsr5EUQk7"
      },
      "source": [
        " ## **Saving the embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZDSpa7tgUQk8",
        "colab": {}
      },
      "source": [
        "item_embedding_path = '/content/drive/My Drive/RS project/modified_item_embedding.npy'\n",
        "user_embedding_path = '/content/drive/My Drive/RS project/modified_user_embedding.npy'\n",
        "model.encode(subset_songs, item_embedding_path, user_embedding_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ra9zo_Q8UQk-"
      },
      "source": [
        " ## **Evaluation**\n",
        " \n",
        "\n",
        "*   Getting the original interaction matrix\n",
        "*   Getting the predicted interaction matrix by applying cosine similarity between the users' and the items' embeddings\n",
        "*   Computing avarage AUC of the original and the predicted interaction matrices\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ym3sF8RWUQlD",
        "colab": {}
      },
      "source": [
        "item_embedding_path = '/content/drive/My Drive/RS project/modified_item_embedding.npy'\n",
        "user_embedding_path = '/content/drive/My Drive/RS project/modified_user_embedding.npy'\n",
        "original_interactions = get_original_interactions(subset_df, subset_users, subset_songs)\n",
        "predicted_interactions = get_predicted_interactions(item_embedding_path, user_embedding_path)\n",
        "auc = get_auc_score(original_interactions[:,train_indices], predicted_interactions[:,train_indices])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD8K-wDy38nW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e8ee2a07-bcf5-4fc3-dff4-a17e1f1b2591"
      },
      "source": [
        "auc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7285648387544025"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}